{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/secutron/Easy-Wav2Lip/blob/v4/Easy_Wav2Lip_V4_fixed_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkoF-mm8CGfB"
      },
      "source": [
        "!!!\n",
        "code from anothermartz and changed for doing......\n",
        "\n",
        "\n",
        "This is the fixed version from when it broke on 11th August 2023 for some reason.\n",
        "\n",
        "Static images don't work on this version, sorry!\n",
        "\n",
        "Please view the GitHub for instructions: https://github.com/anothermartz/Easy-Wav2Lip/blob/v4/README.md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lvmg_zr-9yaZ",
        "outputId": "90d49859-44c3-4ee2-92fa-c7b23330964c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Installation complete, move to Step 2!\n",
            "Execution time: 52s\n"
          ]
        }
      ],
      "source": [
        "#@title <h1>Step 1: Setup \"Easy-Wav2Lip\"</h1> With one button: it's really that easy!\n",
        "#@markdown üëà Click that little circle play button first - it will ask for Google Drive access: <br>\n",
        "#@markdown > Accept if your files are on Google Drive (recommended).\n",
        "#@markdown <br> Alternatively, you can click deny and upload files manually, but this is slower.\n",
        "#check if already installed\n",
        "import os\n",
        "import sys\n",
        "if os.path.exists('/content/Easy-Wav2Lip/installed.txt'):\n",
        "  sys.exit('Step 1 has already been run in this instance! If you want to reinstall go to Runtime > Disconnect and delete runtime')\n",
        "#mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "GDrive = True\n",
        "from google.colab import drive\n",
        "try:\n",
        "  drive.mount('/content/drive')\n",
        "  print(\"You should look for your video in the file browser now while the rest is installing\")\n",
        "except:\n",
        "  from IPython.core.display import clear_output\n",
        "  clear_output()\n",
        "  print(\"...Not mounting Google Drive \\n You should start uploading your video(s) now\")\n",
        "  GDrive = False\n",
        "\n",
        "print()\n",
        "print('Downloading and installing requirements - this usually takes 2-3 minutes, scroll down and start setting up Step 2!')\n",
        "print()\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "import warnings\n",
        "\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import sys\n",
        "#check GPU\n",
        "print(\"Checking GPU is enabled:\")\n",
        "if not tf.test.gpu_device_name():\n",
        "    sys.exit('No GPU in runtime. Please go to the \"Runtime\" menu, \"Change runtime type\" and select \"GPU\".')\n",
        "else:\n",
        "  gpu_name = torch.cuda.get_device_name(0)\n",
        "  gpu_name = gpu_name.replace(' ', '_')\n",
        "  print(f'GPU is {gpu_name}')\n",
        "\n",
        "#imports and stuff\n",
        "import csv\n",
        "import gdown\n",
        "import io\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import requests\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "from base64 import b64encode\n",
        "from numpy.lib import stride_tricks\n",
        "from IPython.display import HTML, Audio, clear_output\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "!git clone -b v4 --single-branch https://github.com/secutron/Easy-Wav2Lip.git\n",
        "os.chdir('Easy-Wav2Lip')\n",
        "os.system('pip3 install -r requirements.txt')\n",
        "from wav2lip_models import Wav2Lip\n",
        "from basicsr.utils.download_util import load_file_from_url\n",
        "from face_parsing import init_parser\n",
        "def load_model(path):\n",
        "    model = Wav2Lip()\n",
        "    print(\"Load checkpoint from: {}\".format(path))\n",
        "    checkpoint = torch.load(path)\n",
        "    s = checkpoint[\"state_dict\"]\n",
        "    new_s = {}\n",
        "    for k, v in s.items():\n",
        "        new_s[k.replace('module.', '')] = v\n",
        "    model.load_state_dict(new_s)\n",
        "    model = model.to(\"cuda\")\n",
        "    return model.eval()\n",
        "#!pip install boto3 --quiet\n",
        "!pip install realesrgan --quiet\n",
        "#clear_output()\n",
        "#import boto3\n",
        "#from botocore.exceptions import NoCredentialsError\n",
        "#!python inference.py --face \"/content/Easy-Wav2Lip/wow.mp4\" --audio \"/content/Easy-Wav2Lip/wow.wav\" --outfile \"/content/Easy-Wav2Lip/initialize/initialized_gfpgan.mp4\" --resize_factor 8 --no_sr\n",
        "#!python inference.py --face \"/content/Easy-Wav2Lip/wow.mp4\" --audio \"/content/Easy-Wav2Lip/wow.wav\" --outfile \"/content/Easy-Wav2Lip/initialize/initialized_gfpgan.mp4\" --resize_factor 8 --enhance_face 'gfpgan'\n",
        "\n",
        "codeformer_initialized = False\n",
        "ESRGAN_initialized = False\n",
        "#!wget 'https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/Eb3LEzbfuKlJiR600lQWRxgBIY27JZg80f7V9jtMfbNDaQ?e=TBFBVW' -O '/content/Easy-Wav2Lip/checkpoints/wav2lip_gan.pth'\n",
        "#!wget \"https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\" -O \"/weights/RealESRGAN_x4plus.pth\"\n",
        "#!wget \"https://github.com/secutron/Easy-Wav2Lip/releases/download/Prerequesits/realesr-general-x4v3.pth\" -O \"/weights/realesr-general-x4v3.pth\"\n",
        "#!wget 'https://github.com/secutron/Easy-Wav2Lip/releases/download/Prerequesits/wav2lip.pth' -O '/content/Easy-Wav2Lip/checkpoints/Wav2Lip.pth'\n",
        "#!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"face_detection/detection/sfd/s3fd.pth\"\n",
        "#clear_output()\n",
        "\n",
        "from esrgan.upsample import load_sr\n",
        "from basicsr.utils.download_util import load_file_from_url\n",
        "import torch, face_detection\n",
        "\n",
        "face_detection.FaceAlignment(face_detection.LandmarksType._2D, flip_input=False, device='cuda')\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "def _load(checkpoint_path):\n",
        "    if device == 'cuda':\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "    else:\n",
        "        checkpoint = torch.load(checkpoint_path,\n",
        "                                map_location=lambda storage, loc: storage)\n",
        "    return checkpoint\n",
        "\n",
        "def load_model(path):\n",
        "    model = Wav2Lip()\n",
        "    print(\"Load checkpoint from: {}\".format(path))\n",
        "    checkpoint = _load(path)\n",
        "    s = checkpoint[\"state_dict\"]\n",
        "    new_s = {}\n",
        "    for k, v in s.items():\n",
        "        new_s[k.replace('module.', '')] = v\n",
        "    model.load_state_dict(new_s)\n",
        "\n",
        "    model = model.to(device)\n",
        "    return model.eval()\n",
        "\n",
        "print(\"Loading segmentation network...\")\n",
        "seg_net = load_file_from_url(\n",
        "  url='https://github.com/anothermartz/Easy-Wav2Lip/releases/download/Prerequesits/face_segmentation.pth',\n",
        "  model_dir='checkpoints', progress=True, file_name=None)\n",
        "seg_net = init_parser('checkpoints/face_segmentation.pth')\n",
        "print(\"Loading super resolution model...\")\n",
        "load_file_from_url(\n",
        "  url='https://github.com/anothermartz/Easy-Wav2Lip/releases/download/Prerequesits/4x_BigFace_v3_Clear.pth',\n",
        "  model_dir='weights', progress=True, file_name=None)\n",
        "run_params = load_sr('weights/4x_BigFace_v3_Clear.pth', 'cuda', 'gfpgan')\n",
        "\n",
        "model_path = load_file_from_url(\n",
        "  url='https://github.com/anothermartz/Easy-Wav2Lip/releases/download/Prerequesits/Wav2Lip.pth',\n",
        "  model_dir='checkpoints', progress=True, file_name='Wav2Lip.pth')\n",
        "model = load_model('/content/Easy-Wav2Lip/checkpoints/Wav2Lip.pth')\n",
        "print (\"Model loaded\")\n",
        "\n",
        "\n",
        "#---------------------------------functions!------------------------------------\n",
        "\n",
        "def showVideo(file_path):\n",
        "  \"\"\"Function to display video in Colab\"\"\"\n",
        "  mp4 = open(file_path,'rb').read()\n",
        "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "  display(HTML(\"\"\"\n",
        "  <video controls width=600>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "  </video>\n",
        "  \"\"\" % data_url))\n",
        "\n",
        "def get_video_details(filename):\n",
        "    cmd = ['ffprobe', '-v', 'error', '-show_format', '-show_streams', '-of', 'json', filename]\n",
        "    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
        "    info = json.loads(result.stdout)\n",
        "\n",
        "    # Get video stream\n",
        "    video_stream = next(stream for stream in info['streams'] if stream['codec_type'] == 'video')\n",
        "\n",
        "    # Get resolution\n",
        "    width = int(video_stream['width'])\n",
        "    height = int(video_stream['height'])\n",
        "    resolution = width*height\n",
        "\n",
        "    # Get fps\n",
        "    fps = eval(video_stream['avg_frame_rate'])\n",
        "\n",
        "    # Get length\n",
        "    length = float(info['format']['duration'])\n",
        "\n",
        "    return {'resolution': resolution, 'fps': fps, 'length': length}\n",
        "\n",
        "def format_time(seconds):\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    seconds = int(seconds % 60)\n",
        "\n",
        "    if hours > 0:\n",
        "        return f'{hours}h {minutes}m {seconds}s'\n",
        "    elif minutes > 0:\n",
        "        return f'{minutes}m {seconds}s'\n",
        "    else:\n",
        "        return f'{seconds}s'\n",
        "\n",
        "def get_input_length(filename):\n",
        "    result = subprocess.run(\n",
        "        [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\",\n",
        "         \"-of\", \"default=noprint_wrappers=1:nokey=1\", filename],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT)\n",
        "    return float(result.stdout)\n",
        "\n",
        "def is_url(string):\n",
        "    url_regex = re.compile(r'^(https?|ftp)://[^\\s/$.?#].[^\\s]*$')\n",
        "    return bool(url_regex.match(string))\n",
        "\n",
        "################################################################################\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "formatted_setup_time = format_time(elapsed_time)\n",
        "with open('installed.txt', 'w') as f:\n",
        "    f.write('Wav2Lip has been installed.')\n",
        "clear_output()\n",
        "print()\n",
        "print(\"Installation complete, move to Step 2!\")\n",
        "print(f\"Execution time: {formatted_setup_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49bpPc22f-wR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290e13a3-13dd-4e4d-dd2a-b1317de6d43b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input video:\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "if not os.path.exists('/content/Easy-Wav2Lip/installed.txt'):\n",
        "  sys.exit('Step 1 has not been run in this instance! Please run step 1 each time you disconnect from a runtime.')\n",
        "\n",
        "############################## user inputs #####################################\n",
        "#@markdown <h1>Step 2: Select inputs:</h1>\n",
        "\n",
        "#@markdown On destktop: <h1></h1>Click the folder icon ( üìÅ ) at the left edge of colab, find your video, right click, copy path, paste it below:\n",
        "#@markdown<br></br>\n",
        "#@markdown On mobile: <h1></h1>Tap the hamburger button ( ‚ò∞ ) at the top left, click show file browser, long tab (hold) on Easy-Wav2Lip, upload, select your file(s), find them in the file browser, copy path, paste below:\n",
        "video_or_image = \"/content/drive/MyDrive/test1.mp4\" #@param {type:\"string\"}\n",
        "vocal_track = \"/content/drive/MyDrive/\\u1112\\u1165\\u11BC\\u1100\\u1173\\u1105\\u1175-short.mp3\" #@param {type:\"string\"}\n",
        "#@markdown > Keep vocal_track blank if your video already has the desired speech audio encoded into it\n",
        "#@markdown\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown<br><br>\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown # [Advanced tweaking](https://github.com/anothermartz/Easy-Wav2Lip#advanced-tweaking) (optional) </h1>Just scroll past all of this if you are new, or click the blue titles for instructions.\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown ### [Upscaling:](https://github.com/anothermartz/Easy-Wav2Lip#upscaling)\n",
        "upscaler = \"gfpgan\" #@param [\"no_upscaling\", \"gfpgan\", \"codeformer\", \"ESRGAN\"]\n",
        "if upscaler == \"codeformer\" and codeformer_initialized==False: # do an initial video process on a tiny file so that downloads don't affect processing time\n",
        "  !python inference.py --face \"/content/Easy-Wav2Lip/wow.mp4\" --audio \"/content/Easy-Wav2Lip/wow.wav\" --outfile \"/content/Easy-Wav2Lip/initialize/initialized_codeformer.mp4\" --resize_factor 8 --enhance_face 'codeformer'\n",
        "  codeformer_initialized = True\n",
        "##@markdown  > I've found that \"gfpgan\" always gives the best results but maybe other models work better for other content. <br> For the fastest processing time use \"no_upscaling\".\n",
        "default_ESRGAN_model = \"/content/Easy-Wav2Lip/weights/weights/4x_BigFace_v3_Clear.pth\"\n",
        "ESRGAN_model = \"/content/Easy-Wav2Lip/weights/weights/4x_BigFace_v3_Clear.pth\" #@param [\"/content/Easy-Wav2Lip/weights/RealESRGAN_x4plus.pth\"] {allow-input: true}\n",
        "if upscaler == \"ESRGAN\":\n",
        "  if not os.path.exists(ESRGAN_model):\n",
        "    sys.exit(\"ESRGAN_model specified is not found\")\n",
        "##@markdown  > For use with 'ESRGAN' option only.\n",
        "codeformer_fidelity = 0.75 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "##@markdown > For use with 'codeformer' option only.\n",
        "#@markdown <br></br>\n",
        "#@markdown ### [Padding:](https://github.com/anothermartz/Easy-Wav2Lip#tweak-padding)</h1> (Up, Down, Left, Right) <br>\n",
        "U = 0 #@param {type:\"slider\", min:-40, max:100, step:5}\n",
        "D = 10 #@param {type:\"slider\", min:-40, max:100, step:5}\n",
        "L = 0 #@param {type:\"slider\", min:-40, max:100, step:5}\n",
        "R = 0 #@param {type:\"slider\", min:-40, max:100, step:5}\n",
        "#@markdown <br></br>\n",
        "#@markdown # [Batch Processing:](https://github.com/anothermartz/Easy-Wav2Lip#batch-processing)\n",
        "batch_process = True #@param {type:\"boolean\"}\n",
        "#@markdown <br></br>\n",
        "#@markdown # [Other options:](https://github.com/anothermartz/Easy-Wav2Lip#other-options)\n",
        "resolution_scale =  1 #@param {type:\"slider\", min:0.25, max:1, step:0.25}\n",
        "fps_for_static_image = 30 #@param {type:\"number\"}\n",
        "nosmooth = True #@param {type:\"boolean\"}\n",
        "output_suffix = \"_EasyWav2Lip\" #@param {type:\"string\"}\n",
        "include_upscaler_in_suffix = True #@param {type:\"boolean\"}\n",
        "if include_upscaler_in_suffix:\n",
        "  if upscaler==\"ESRGAN\":\n",
        "    output_suffix = output_suffix + \"_\" + re.search(r\"[^\\/]+(?=\\.\\w+$)\", ESRGAN_model).group()\n",
        "  elif upscaler==\"codeformer\":\n",
        "    output_suffix = f'{output_suffix}_{upscaler}_' + str(codeformer_fidelity).replace(\".\", \"_\")\n",
        "  else:\n",
        "    output_suffix = f'{output_suffix}_{upscaler}'\n",
        "preview_input = True #@param {type:\"boolean\"}\n",
        "#------------------------------*Step 3*----------------------------------------!\n",
        "#@markdown <h1><br>üëà Step 3:  Click the little circle play button on this cell! </h1> (Or press ctrl + F10) - Then wait for processing to complete.\n",
        "# scale padding with resolution\n",
        "rescaleFactor = str(round(1 // resolution_scale))\n",
        "pad_up = str(round(U * resolution_scale))\n",
        "pad_down = str(round(D * resolution_scale))\n",
        "pad_left = str(round(L * resolution_scale))\n",
        "pad_right = str(round(R * resolution_scale))\n",
        "################################################################################\n",
        "\n",
        "\n",
        "######################### reconstruct input paths ##############################\n",
        "# check video_or_image exists\n",
        "if not os.path.exists(video_or_image):\n",
        "  sys.exit(f'Could not find file: {video_or_image}')\n",
        "# extract each part of the path\n",
        "filename = re.search(r\"[^\\/]+(?=\\.\\w+$)\", video_or_image).group()\n",
        "file_type = os.path.splitext(video_or_image)[1]\n",
        "folder = re.search(r\"^(.*\\/)[^\\/]+$\", video_or_image).group(1)\n",
        "filenumber_match = re.search(r\"\\d+$\", filename)\n",
        "if filenumber_match: # if there is a filenumber - extract it\n",
        "  filenumber = str(filenumber_match.group())\n",
        "  filenamenonumber = re.sub(r\"\\d+$\", \"\", filename)\n",
        "else: # if there is no filenumber - make it blank\n",
        "  filenumber = \"\"\n",
        "  filenamenonumber = filename\n",
        "\n",
        "# if vocal_track is blank - use the video as audio\n",
        "if vocal_track == \"\":\n",
        "  vocal_track = video_or_image\n",
        "# if not, check that the vocal_track file exists\n",
        "else:\n",
        "  if not os.path.exists(vocal_track):\n",
        "    sys.exit(f'Could not find file: {vocal_track}')\n",
        "# extract each part of the path:\n",
        "audio_filename = re.search(r\"[^\\/]+(?=\\.\\w+$)\", vocal_track).group()\n",
        "audio_file_type = os.path.splitext(vocal_track)[1]\n",
        "audio_folder = re.search(r\"^(.*\\/)[^\\/]+$\", vocal_track).group(1)\n",
        "audio_filenumber_match = re.search(r\"\\d+$\", audio_filename)\n",
        "if audio_filenumber_match: #if there is a filenumber - extract it\n",
        "  audio_filenumber = str(audio_filenumber_match.group())\n",
        "  audio_filenamenonumber = re.sub(r\"\\d+$\", \"\", audio_filename)\n",
        "else: # if there is no filenumber - make it blank\n",
        "  audio_filenumber = \"\"\n",
        "  audio_filenamenonumber = audio_filename\n",
        "################################################################################\n",
        "\n",
        "# set process_failed to False so that it may be set to True if one or more processings fail\n",
        "process_failed = False\n",
        "temp_output = '/content/Easy-Wav2Lip/temp/output.mp4'\n",
        "temp_folder = '/content/Easy-Wav2Lip/temp/'\n",
        "last_input_video = None\n",
        "last_input_audio = None\n",
        "\n",
        "#if file_type == '.gif':\n",
        "#  sys.exit(\"I'm sorry but .gif files aren't supported!\")\n",
        "\n",
        "#if file_type == '.jpg' or '.jpeg' or '.png' or '.bmp' or '.tiff' or '.tif':\n",
        "#  input_is_image = True\n",
        "#else:\n",
        "#  input_is_image = False\n",
        "\n",
        "\n",
        "#--------------------------Batch processing loop-------------------------------!\n",
        "while True:\n",
        "\n",
        "  # construct input_video\n",
        "  input_video = folder + filenamenonumber + str(filenumber) + file_type\n",
        "  input_videofile = re.search(r\"[^\\/]+$\", input_video).group()\n",
        "  # construct input_audio\n",
        "  input_audio = audio_folder + audio_filenamenonumber + str(audio_filenumber) + audio_file_type\n",
        "  input_audiofile = re.search(r\"[^\\/]+$\", input_audio).group()\n",
        "  # see if filenames are different:\n",
        "  if filenamenonumber + str(filenumber) != audio_filenamenonumber + str(audio_filenumber):\n",
        "    output_filename = filenamenonumber + str(filenumber) + \"_\" + audio_filenamenonumber + str(audio_filenumber)\n",
        "  else:\n",
        "    output_filename = filenamenonumber + str(filenumber)\n",
        "  # construct output_video\n",
        "  output_video = folder + output_filename + output_suffix + '.mp4'\n",
        "  output_videofile = re.search(r\"[^\\/]+$\", output_video).group()\n",
        "\n",
        "  # remove last outputs\n",
        "  directory_path = \"/content/Easy-Wav2Lip/temp\"\n",
        "  if os.path.exists(directory_path):\n",
        "    shutil.rmtree(directory_path)\n",
        "  os.makedirs(directory_path)\n",
        "\n",
        "  # preview inputs (if enabled)\n",
        "  if preview_input:\n",
        "    print(\"input video:\")\n",
        "    showVideo(input_video)\n",
        "    if vocal_track != \"\":\n",
        "      print(\"input audio:\")\n",
        "      display(Audio(input_audio))\n",
        "    else:\n",
        "      print(\"using\", input_video, \"for audio\")\n",
        "    print(\"You may want to check now that they're the correct files!\")\n",
        "\n",
        "  last_input_video = input_video\n",
        "  last_input_audio = input_audio\n",
        "  shutil.copy(input_video, temp_folder)\n",
        "  shutil.copy(input_audio, temp_folder)\n",
        "  temp_input_video = temp_folder + input_videofile\n",
        "  temp_input_audio = temp_folder + input_audiofile\n",
        "\n",
        "  #----------------------------Process the inputs!-----------------------------!\n",
        "  print(f\"Processing {input_videofile} using {input_audiofile} for audio\")\n",
        "  #start processing timer\n",
        "  start_time = time.time()\n",
        "\n",
        "\n",
        "  #execute Wav2Lip & upscaler\n",
        "  !python 'inference.py' \\\n",
        "  --face \"{temp_input_video}\" \\\n",
        "  --audio \"{temp_input_audio}\" \\\n",
        "  --outfile \"{temp_output}\" \\\n",
        "  --pads $pad_up $pad_down $pad_left $pad_right \\\n",
        "  --checkpoint_path '/content/Easy-Wav2Lip/checkpoints/Wav2Lip.pth' \\\n",
        "  --resize_factor $rescaleFactor \\\n",
        "  --fps \"{fps_for_static_image}\" \\\n",
        "  {'--nosmooth ' if nosmooth else ''} {'--no_sr ' if upscaler=='no_upscaling' else ''} {'--enhance_face gfpgan ' if upscaler == 'gfpgan' else ''} {'-w ' + str(codeformer_fidelity) + ' --enhance_face codeformer ' if upscaler == \"codeformer\" else ''} {'--sr_path ' + ESRGAN_model if upscaler == \"ESRGAN\" else ''}\n",
        "\n",
        "  #end processing timer and format the time it took\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  process_time = int(elapsed_time)\n",
        "  formatted_process_time = format_time(elapsed_time)\n",
        "\n",
        "  #rename temp file and move to correct directory\n",
        "  if os.path.isfile(temp_output):\n",
        "    if os.path.isfile(output_video):\n",
        "      os.remove(output_video)\n",
        "    !cp \"{temp_output}\" \"{output_video}\"\n",
        "    if os.path.isfile(output_video):\n",
        "      #show output video\n",
        "      clear_output()\n",
        "      print(f\"{output_filename} successfully lip synced! Find it in the same folder as your input file(s).\")\n",
        "  if os.path.isfile(temp_output):\n",
        "    print(\"Loading video preview...\")\n",
        "    showVideo(temp_output)\n",
        "  else:\n",
        "    print(f\"Processing failed! :( see line above üëÜ\")\n",
        "    process_failed = True\n",
        "\n",
        "  if batch_process == False:\n",
        "    print(\"Batch Processing disabled\")\n",
        "    if process_failed:\n",
        "      if upscaler == \"ESRGAN\" and ESRGAN_model != default_ESRGAN_model:\n",
        "        sys.exit(\"Processing failed - likely caused by custom ESRGAN model - try a different one!\")\n",
        "      else:\n",
        "        sys.exit(\"Processing failed\")\n",
        "    else:\n",
        "      break\n",
        "  elif filenumber == \"\" and audio_filenumber == \"\":\n",
        "    print('Files not set for batch processing')\n",
        "    break\n",
        "\n",
        "  #Batch processing\n",
        "  if filenumber != \"\": # if video has a filenumber\n",
        "    match = re.search(r'\\d+', filenumber)\n",
        "    # add 1 to video filenumber\n",
        "    filenumber = f\"{filenumber[:match.start()]}{int(match.group())+1:0{len(match.group())}d}\"\n",
        "\n",
        "  if audio_filenumber != \"\": # if audio has a filenumber\n",
        "    match = re.search(r'\\d+', audio_filenumber)\n",
        "    # add 1 to audio filenumber\n",
        "    audio_filenumber = f\"{audio_filenumber[:match.start()]}{int(match.group())+1:0{len(match.group())}d}\"\n",
        "\n",
        "  # construct input_video\n",
        "  input_video = folder + filenamenonumber + str(filenumber) + file_type\n",
        "  input_videofile = re.search(r\"[^\\/]+$\", input_video).group()\n",
        "  # construct input_audio\n",
        "  input_audio = audio_folder + audio_filenamenonumber + str(audio_filenumber) + audio_file_type\n",
        "  input_audiofile = re.search(r\"[^\\/]+$\", input_audio).group()\n",
        "\n",
        "  # now check which input files exist and what to do for each scenario\n",
        "\n",
        "  # both +1 files exist - continue processing\n",
        "  if os.path.exists(input_video) and os.path.exists(input_audio):\n",
        "    continue\n",
        "\n",
        "  # video +1 only - continue with last audio file\n",
        "  if os.path.exists(input_video) and input_video != last_input_video:\n",
        "    if audio_filenumber != \"\": # if audio has a filenumber\n",
        "        match = re.search(r'\\d+', audio_filenumber)\n",
        "        # take 1 from audio filenumber\n",
        "        audio_filenumber = f\"{audio_filenumber[:match.start()]}{int(match.group())-1:0{len(match.group())}d}\"\n",
        "    continue\n",
        "\n",
        "  # audio +1 only - continue with last video file\n",
        "  if os.path.exists(input_audio) and input_audio != last_input_audio:\n",
        "    if filenumber != \"\": # if video has a filenumber\n",
        "      match = re.search(r'\\d+', filenumber)\n",
        "      # take 1 from video filenumber\n",
        "      filenumber = f\"{filenumber[:match.start()]}{int(match.group())-1:0{len(match.group())}d}\"\n",
        "    continue\n",
        "\n",
        "  # neither +1 files exist or current files already processed - finish processing\n",
        "  print(\"Finished all sequentially numbered files\")\n",
        "  if process_failed:\n",
        "    if upscaler == \"ESRGAN\" and ESRGAN_model != default_ESRGAN_model:\n",
        "      sys.exit(\"Processing failed - likely caused by custom ESRGAN model - try a different one!\")\n",
        "    else:\n",
        "      sys.exit(\"Processing failed on at least one video\")\n",
        "  else:\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}