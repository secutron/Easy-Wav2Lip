{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anothermartz/Easy-Wav2Lip/blob/main/Easy-Wav2Lip_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkoF-mm8CGfB"
      },
      "source": [
        "Make sure to click ðŸ‘† that button to copy it your own Google Drive first!\n",
        "\n",
        "# Wav2Lip-HQ made easy!\n",
        "\n",
        "GitHub: https://github.com/anothermartz/Easy-Wav2Lip\n",
        "\n",
        "* Code adapted to google colab from [wav2lip-hq-updated-ESRGAN](https://github.com/GucciFlipFlops1917/wav2lip-hq-updated-ESRGAN) by [GucciFlipFlops1917](https://github.com/GucciFlipFlops1917)\n",
        "\n",
        "* Which fixes and improves the depreciated [Wav2LipHQ](https://github.com/Markfryazino/wav2lip-hq)\n",
        "\n",
        "* Which is based on the original [Wav2Lip](https://github.com/Rudrabha/Wav2Lip)\n",
        "\n",
        "Not only was this built on the shoulders of giants, I'm not even very good at coding and I practically used Bing AI chat to do it all for me.\n",
        "\n",
        "However I may offer some support in this discord:<br>\n",
        "Invite link: https://discord.gg/FNZR9ETwKY<br>\n",
        "Wav2Lip channel: https://discord.com/channels/667279414681272320/1076077584330280991"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFOs0q_SKzqG"
      },
      "source": [
        "# Best practices:\n",
        "Video files:\n",
        "* Must have a face in all frames or Wav2Lip will fail\n",
        "* Use h264 .mp4 - other file types may be supported but this definitely works\n",
        "* Use a small file in every way (try <720p, <60 seconds, 30fps <b></b> etc. - Bigger files may work but are usually the reason it fails)\n",
        "* Start with a really tiny clip just to get used to the process, don't go throwing in a huge file for your first try.\n",
        "\n",
        "Audio files:\n",
        "* Ideally just encode it into your video file\n",
        "* <b>OR</b>\n",
        "* Name the audio file the same as the video eg: Video.mp4 & Video.wav\n",
        "* Must be .wav\n",
        "  \n",
        "I may include support for other types later as I think Wav2Lip does, but right now the code only accounts for .wav.\n",
        "\n",
        "Batch processing:\n",
        "* Name files you want to be processed in a batch ending in a number\n",
        "eg: Video1.mp4, Video2.mp4, Video3.mp4 etc. and have them all in the same folder.\n",
        "\n",
        "If you select Video3.mp4 to process, it will look for Video4.mp4 etc. afterwards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lvmg_zr-9yaZ"
      },
      "outputs": [],
      "source": [
        "#@title <h1>Step 1: Setup \"Easy-Wav2Lip\"</h1> With one button: it's really that easy!\n",
        "#@markdown 1. ðŸ‘ˆ Click that little circle play button - it will ask for Google Drive access\n",
        "#@markdown 2. Accept if your files are on Google Drive (recommended)\n",
        "#@markdown <br><br> Alternatively, say \"no thanks\" and click the folder icon to the far left, right click and upload your files there.<br>If not using Google Drive, you may lose all processed files if not manually downloaded.\n",
        "\n",
        "#mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "GDrive = True\n",
        "from google.colab import drive\n",
        "try:\n",
        "  drive.mount('/content/drive')\n",
        "  print(\"You should look for your video in the file browser now while the rest is installing\")\n",
        "except:\n",
        "  from IPython.core.display import clear_output\n",
        "  clear_output()\n",
        "  print(\"...Not mounting Google Drive \\n You should start uploading your video(s) now\")\n",
        "  GDrive = False\n",
        "\n",
        "print()\n",
        "print('Downloading and installing requirements - this usually takes 2-3 minutes, scroll down and start setting up Step 2!')\n",
        "print()\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "import warnings\n",
        "\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import sys\n",
        "#check GPU\n",
        "print(\"Checking GPU is enabled:\")\n",
        "if not tf.test.gpu_device_name():\n",
        "    sys.exit('No GPU in runtime. Please go to the \"Runtime\" menu, \"Change runtime type\" and select \"GPU\".')\n",
        "else:\n",
        "  gpu_name = torch.cuda.get_device_name(0)\n",
        "  gpu_name = gpu_name.replace(' ', '_')\n",
        "  print(f'GPU is {gpu_name}')\n",
        "\n",
        "#imports and stuff\n",
        "import csv\n",
        "import gdown\n",
        "import io\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "from base64 import b64encode\n",
        "from numpy.lib import stride_tricks\n",
        "from IPython.display import HTML, Audio, clear_output\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.system('git clone https://github.com/anothermartz/Easy-Wav2Lip.git')\n",
        "os.chdir('Easy-Wav2Lip')\n",
        "os.system('pip3 install -r requirements.txt') \n",
        "from wav2lip_models import Wav2Lip\n",
        "from basicsr.utils.download_util import load_file_from_url\n",
        "from face_parsing import init_parser\n",
        "def load_model(path):\n",
        "    model = Wav2Lip()\n",
        "    print(\"Load checkpoint from: {}\".format(path))\n",
        "    checkpoint = torch.load(path)\n",
        "    s = checkpoint[\"state_dict\"]\n",
        "    new_s = {}\n",
        "    for k, v in s.items():\n",
        "        new_s[k.replace('module.', '')] = v\n",
        "    model.load_state_dict(new_s)\n",
        "    model = model.to(\"cuda\")\n",
        "    return model.eval()\n",
        "!pip install boto3 --quiet\n",
        "!pip install realesrgan --quiet\n",
        "#clear_output()\n",
        "import boto3\n",
        "from botocore.exceptions import NoCredentialsError\n",
        "#pre-download all models so that Step 2 is faster - I don't know how else to download gfpgan and codeformer files than to run them so I include a tiny video to process quickly.\n",
        "!wget \"https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\" -O \"/content/Easy-Wav2Lip/weights/RealESRGAN_x4plus.pth\"\n",
        "!python inference.py --face \"/content/Easy-Wav2Lip/temp/initialize.mp4\" --audio \"/content/Easy-Wav2Lip/temp/initialize.mp4\" --outfile \"/content/Easy-Wav2Lip/temp/initialized_gfpgan.mp4\" --resize_factor 8 --enhance_face 'gfpgan'\n",
        "!python inference.py --face \"/content/Easy-Wav2Lip/temp/initialize.mp4\" --audio \"/content/Easy-Wav2Lip/temp/initialize.mp4\" --outfile \"/content/Easy-Wav2Lip/temp/initialized_codeformer.mp4\" --resize_factor 8 --enhance_face 'codeformer'\n",
        "#!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"face_detection/detection/sfd/s3fd.pth\"\n",
        "#clear_output()\n",
        "print('Downloading and installing requirements - this usually takes about 3 minutes, scroll down and start setting up Step 2!')\n",
        "print()\n",
        "\n",
        "#---------------------------------functions!------------------------------------\n",
        "\n",
        "def showVideo(file_path):\n",
        "  \"\"\"Function to display video in Colab\"\"\"\n",
        "  mp4 = open(file_path,'rb').read()\n",
        "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "  display(HTML(\"\"\"\n",
        "  <video controls width=600>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "  </video>\n",
        "  \"\"\" % data_url))\n",
        "\n",
        "def get_video_details(filename):\n",
        "    cmd = ['ffprobe', '-v', 'error', '-show_format', '-show_streams', '-of', 'json', filename]\n",
        "    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
        "    info = json.loads(result.stdout)\n",
        "\n",
        "    # Get video stream\n",
        "    video_stream = next(stream for stream in info['streams'] if stream['codec_type'] == 'video')\n",
        "\n",
        "    # Get resolution\n",
        "    width = int(video_stream['width'])\n",
        "    height = int(video_stream['height'])\n",
        "    resolution = width*height\n",
        "\n",
        "    # Get fps\n",
        "    fps = eval(video_stream['avg_frame_rate'])\n",
        "\n",
        "    # Get length\n",
        "    length = float(info['format']['duration'])\n",
        "\n",
        "    return {'resolution': resolution, 'fps': fps, 'length': length}\n",
        "\n",
        "def predict_processing_time(input_resolution, input_fps, input_length, resolution_scale, upscaler):\n",
        "    filename = f'{upscaler}_with_{gpu_name}_processing_stats.csv'\n",
        "    try:\n",
        "        # Load the data from the CSV file\n",
        "        data = pd.read_csv(filename, header=None)\n",
        "    except FileNotFoundError:\n",
        "        return None\n",
        "\n",
        "    # Split the data into input features and target variable\n",
        "    X = data.iloc[:, :-1]\n",
        "    y = data.iloc[:, -1]\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    # Train a random forest regressor on the training data\n",
        "    regressor = RandomForestRegressor()\n",
        "    regressor.fit(X_train, y_train)\n",
        "\n",
        "    # Calculate the R-squared value on the test set\n",
        "    r_squared = regressor.score(X_test, y_test)\n",
        "\n",
        "    # Create a new row of data for the new video\n",
        "    new_video = [input_resolution, input_fps, input_length, resolution_scale]\n",
        "\n",
        "    # Predict the processing time of the new video\n",
        "    predicted_time = regressor.predict([new_video])\n",
        "    \n",
        "    return predicted_time, r_squared\n",
        "\n",
        "def format_time(seconds):\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    seconds = int(seconds % 60)\n",
        "    \n",
        "    if hours > 0:\n",
        "        return f'{hours}h {minutes}m {seconds}s'\n",
        "    elif minutes > 0:\n",
        "        return f'{minutes}m {seconds}s'\n",
        "    else:\n",
        "        return f'{seconds}s'\n",
        "\n",
        "def store_processing_stats(input_resolution, input_fps, input_length, resolution_scale, upscaler, process_time):\n",
        "    filename = f'{upscaler}_with_{gpu_name}_processing_stats.csv'\n",
        "    with open(filename, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([input_resolution, input_fps, input_length, resolution_scale, process_time])\n",
        "\n",
        "\n",
        "def count_lines(stats_file):\n",
        "    with open(stats_file, 'r') as f:\n",
        "        return sum(1 for line in f)\n",
        "\n",
        "def remove_duplicates(stats_file):\n",
        "    df = pd.read_csv(stats_file)\n",
        "    df = df.drop_duplicates()\n",
        "    df.to_csv(stats_file, index=False)\n",
        "\n",
        "def getkeys():\n",
        "    import gdown\n",
        "    import zipfile\n",
        "    import os\n",
        "    import boto3\n",
        "    url = 'https://drive.google.com/uc?id=1nXL-wQ2B9sxny9TwjWAKwQRi7Rs-Pmis'\n",
        "    zip_path = '/content/Easy-Wav2Lip/temp/pdata.zip'\n",
        "    gdown.download(url, zip_path, quiet=True)\n",
        "    txt_path = '/content/Easy-Wav2Lip/temp/pdata.txt'\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/Easy-Wav2Lip/temp/')\n",
        "    with open(txt_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        s3_folder = lines[0].strip()\n",
        "        s3_access_key = lines[1].strip()\n",
        "        s3_secret_key = lines[2].strip()\n",
        "        bucket_name = lines[3].strip()\n",
        "    os.remove(zip_path)\n",
        "    os.remove(txt_path)\n",
        "    s3 = boto3.client('s3', aws_access_key_id=s3_access_key, aws_secret_access_key=s3_secret_key)\n",
        "    return s3, s3_folder, bucket_name\n",
        "\n",
        "s3, s3_folder, bucket_name = getkeys()\n",
        "################################################################################\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "formatted_setup_time = format_time(elapsed_time)\n",
        "\n",
        "clear_output()\n",
        "print()\n",
        "print(\"Installation complete, move to Step 2!\")\n",
        "print(f\"Execution time: {formatted_setup_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "49bpPc22f-wR"
      },
      "outputs": [],
      "source": [
        "#------------------------------user inputs--------------------------------------\n",
        "#@markdown <h1>Step 2: Select video:</h1>\n",
        "#@markdown ðŸ‘ˆ Look for the folder icon at the left edge of colab and find your video, right click it, copy path & paste it below:\n",
        "input_path = \"\" #@param {type:\"string\"}\n",
        "#Batch_Process= True #@param {type:\"boolean\"}\n",
        "##@markdown >Disable if you just want to process one video (good for testing or fixing padding).\n",
        "output_suffix = \"_Wav2LipHQ\" #@param {type:\"string\"}\n",
        "#@markdown >This adds a suffix to your output files so that they don't overwite your originals\n",
        "preview_input = False #@param {type:\"boolean\"}\n",
        "#@markdown >Displays the video/audio while Wav2Lip does its thing, disabling saves some seconds.\n",
        "#@markdown <h1><br>Step 3: Tweak padding (optional):</h1> (Up, Down, Left, Right) <br>\n",
        "#@markdown <b><br>Lower values typically look better on the mouth but can cause hard lines at the edges of the face (typically on the chin)</b>\n",
        "U = 0 #@param {type:\"slider\", min:-40, max:100, step:5}\n",
        "D =  25 #@param {type:\"slider\", min:-40, max:100, step:5}\n",
        "L =  0 #@param {type:\"slider\", min:-40, max:100, step:5}\n",
        "R =  0 #@param {type:\"slider\", min:-40, max:100, step:5}\n",
        "#@markdown Lower the output resolution for quicker rendering and better hiding of artifacts, at the cost of worse overall image quality:\n",
        "resolution_scale =  1 #@param {type:\"slider\", min:0.25, max:1, step:0.25}\n",
        "#@markdown Disable face detection smoothing which may fix artifacts, I'm not aware of any downsides to this:\n",
        "nosmooth = True #@param {type:\"boolean\"}\n",
        "#@markdown <h1><br>Step 4: Choose Upscaler Method (optional):</h1> I suggest gfpgan but you can experiment with the others <br>\n",
        "upscaler = \"ESRGAN\" #@param [\"gfpgan\", \"codeformer\", \"ESRGAN\"]\n",
        "#@markdown for use with codeformer only:\n",
        "fidelity = 0.75 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "#@markdown <h1></h1> I recommend 0.75 but have a play around to see what you like\n",
        "#@markdown <h1><br>Step 5: Click the circle play button for this cell and wait for processing to complete.</h1>\n",
        "batch_process = True #@param {type:\"boolean\"}\n",
        "#@markdown See \"Best Practices\" at the top of this page for how to set your files correctly for batch processing.\n",
        "################################################################################\n",
        "\n",
        "#convert user inputs\n",
        "rescaleFactor = str(round(1 // resolution_scale))\n",
        "pad_up = str(round(U * resolution_scale))\n",
        "pad_down = str(round(D * resolution_scale))\n",
        "pad_left = str(round(L * resolution_scale))\n",
        "pad_right = str(round(R * resolution_scale))\n",
        "\n",
        "#custom checkpoints coming soonâ„¢\n",
        "ESRGAN_checkpoint = \"/weights/RealESRGAN_x4plus.pth\"\n",
        "\n",
        "#--------------------------deconstruct input_path------------------------------!\n",
        "if os.path.exists(input_path):\n",
        "  # Extract each part of input_path\n",
        "  filename = re.search(r\"[^\\/]+(?=\\.\\w+$)\", input_path).group()\n",
        "  file_type = os.path.splitext(input_path)[1]\n",
        "  folder = re.search(r\"^(.*\\/)[^\\/]+$\", input_path).group(1)\n",
        "  filenumber_match = re.search(r\"\\d+$\", filename)\n",
        "  if filenumber_match:\n",
        "    filenumber = str(filenumber_match.group())\n",
        "    filenamenonumber = re.sub(r\"\\d+$\", \"\", filename)\n",
        "    #need to -1 now because the loop starts by adding 1\n",
        "    for i in range(1):\n",
        "        # Your other code here\n",
        "        match = re.search(r'\\d+', filenumber)\n",
        "        num_str = match.group()\n",
        "        num_len = len(num_str)\n",
        "        num = int(num_str) - 1\n",
        "        filenumber = f\"{filenumber[:match.start()]}{num:0{num_len}d}\"\n",
        "  else:\n",
        "    filenumber = None\n",
        "    filenamenonumber = filename\n",
        "else: \n",
        "    sys.exit(f'Could not find file: {input_path}')\n",
        "################################################################################\n",
        "\n",
        "#--------------------------Batch processing loop-------------------------------!\n",
        "while True:\n",
        "  if filenumber != None:\n",
        "    #add 1 to the file number to process the next file\n",
        "    for i in range(1):\n",
        "        # Your other code here\n",
        "        match = re.search(r'\\d+', filenumber)\n",
        "        num_str = match.group()\n",
        "        num_len = len(num_str)\n",
        "        num = int(num_str) + 1\n",
        "        filenumber = f\"{filenumber[:match.start()]}{num:0{num_len}d}\"\n",
        "\n",
        "    #construct input_video\n",
        "    input_video = folder + filenamenonumber + str(filenumber) + file_type\n",
        "  else:\n",
        "    input_video = folder + filenamenonumber + file_type\n",
        "  input_videofile = re.search(r\"[^\\/]+$\", input_video).group()\n",
        "  temp_input = \"/content/Easy-Wav2Lip/temp/input.mp4\"\n",
        "  temp_wav = \"/content/Easy-Wav2Lip/temp/input_audio.wav\"\n",
        "  temp_avi = '/content/Easy-Wav2Lip/temp/result.avi'\n",
        "  if os.path.exists(input_video):\n",
        "    print(\"Processing\" , input_videofile)\n",
        "  else:\n",
        "    print(\"Finished all sequentially numbered files\")\n",
        "    print(input_video)\n",
        "    break\n",
        "\n",
        "  #construct input_audio\n",
        "  if filenumber != None:\n",
        "    input_audio = folder + filenamenonumber + str(filenumber) + \".wav\"\n",
        "  else:\n",
        "    input_audio = folder + filenamenonumber + \".wav\"\n",
        "  input_audiofile = re.search(r\"[^\\/]+$\", input_audio).group()\n",
        "\n",
        "  #construct output_video\n",
        "  if filenumber != None:\n",
        "    output_video = folder + filenamenonumber + str(filenumber) + output_suffix + \".mp4\"\n",
        "    output_filename = filenamenonumber + str(filenumber) + output_suffix + \".mp4\"\n",
        "  else:\n",
        "    output_video = folder + filenamenonumber + output_suffix + \".mp4\"\n",
        "    output_filename = filenamenonumber + output_suffix + \".mp4\"\n",
        "  temp_output = \"/content/Easy-Wav2Lip/temp/output.mp4\"\n",
        "\n",
        "  #remove last outputs\n",
        "  directory_path = \"/content/Easy-Wav2Lip/temp\"\n",
        "  if os.path.exists(directory_path):\n",
        "    shutil.rmtree(directory_path)\n",
        "  os.makedirs(directory_path)\n",
        "\n",
        "  #copy video\n",
        "  !cp \"{input_video}\" \"{temp_input}\"\n",
        "\n",
        "  #look for audio file\n",
        "  if os.path.isfile(input_audio):\n",
        "    !cp \"{input_audio}\" \"{temp_wav}\"\n",
        "    if preview_input:\n",
        "      print(\"loading input video preview:\")\n",
        "      showVideo(input_video)\n",
        "      print(\"input audio:\" , input_audio)\n",
        "      display(Audio(temp_wav))\n",
        "      print(\"You may want to check now that they're the correct files!\")\n",
        "    else:\n",
        "      print(\"using\", input_audiofile, \"for audio\")\n",
        "\n",
        "  #take audio from video file\n",
        "  else:\n",
        "    temp_wav = temp_input\n",
        "    print(\"Using audio from video file\")\n",
        "    if preview_input:\n",
        "      print(\"loading input video preview:\")\n",
        "      showVideo(input_video)\n",
        "      print(\"You may want to check now that it's the correct video!\")\n",
        "  ################################################################################\n",
        "\n",
        "  #-------------------------process length prediction-----------------------------\n",
        "  details = get_video_details(temp_input)\n",
        "  input_resolution = int(details['resolution'])\n",
        "  input_fps = int(details['fps'])\n",
        "  input_length = float(details['length'])\n",
        "  new_video_resolution = input_resolution\n",
        "  new_video_fps = input_fps\n",
        "  new_video_length = input_length\n",
        "  new_video_resolution_scale = resolution_scale\n",
        "  new_video_upscaler = upscaler\n",
        "  stats_file = f'{upscaler}_with_{gpu_name}_processing_stats.csv'\n",
        "  object_key = 'wav2lip/' + stats_file\n",
        "  num_lines = 1\n",
        "  try:\n",
        "      s3.head_object(Bucket=bucket_name, Key=object_key)\n",
        "      s3.download_file(bucket_name, object_key, stats_file)\n",
        "      print(f\"found prediction data for {gpu_name} with {upscaler}\")\n",
        "      remove_duplicates(stats_file)\n",
        "      num_lines = count_lines(stats_file)\n",
        "  except:\n",
        "      predicted_time = None\n",
        "      print(f\"no prediction data for {gpu_name} with {upscaler} yet\")\n",
        "  if num_lines < 10:\n",
        "    print('But there isn\\'t enough prediction data for that combo yet to predict a processing time')\n",
        "    predicted_time = None\n",
        "  else:\n",
        "    try:\n",
        "      predicted_time, r_squared = predict_processing_time(input_resolution, input_fps, input_length, resolution_scale, upscaler)\n",
        "      if r_squared <0:\n",
        "        print('Not much prediction data so prediction is unlikely to be accurate, but the more people process videos, the better it will get!')\n",
        "      if predicted_time is not None:\n",
        "        formatted_time = format_time(predicted_time[0])\n",
        "        confidence = '(~' + str(max(int(r_squared * 100),1)) + \"% confidence)\"\n",
        "        print()\n",
        "        print(f'Predicted processing time for this video is: {formatted_time} {confidence}')\n",
        "        print()\n",
        "    except:\n",
        "      print(f'unknown error trying to predict processing time :(')\n",
        "  ################################################################################\n",
        "\n",
        "  #start processing timer\n",
        "  start_time = time.time()\n",
        "\n",
        "  #execute Wav2Lip & upscaler\n",
        "  !python inference.py \\\n",
        "  --face \"{temp_input}\" \\\n",
        "  --audio \"{temp_wav}\" \\\n",
        "  --outfile \"{temp_output}\" \\\n",
        "  --pads $pad_up $pad_down $pad_left $pad_right \\\n",
        "  --resize_factor $rescaleFactor \\\n",
        "  {'--nosmooth ' if nosmooth else ''} {'-w ' + str(fidelity) if upscaler == \"codeformer\" else ''} {'--sr_path ' + ESRGAN_checkpoint if upscaler == \"ESRGAN\" else '--enhance_face ' + upscaler}\n",
        "\n",
        "  #end processing timer\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  process_time = int(elapsed_time)\n",
        "  formatted_process_time = format_time(elapsed_time)\n",
        "\n",
        "  #rename temp file and move to correct directory\n",
        "  if os.path.isfile(temp_output):\n",
        "    if os.path.isfile(output_video):\n",
        "      os.remove(output_video)\n",
        "    !cp \"{temp_output}\" \"{output_video}\"\n",
        "    if os.path.isfile(output_video):\n",
        "      #show output video\n",
        "      clear_output()\n",
        "      print(f\"{output_filename} successfully lip synched! Find it in the same folder as your input file(s).\")\n",
        "      if predicted_time is not None: \n",
        "       print(f'Predicted processing time for this video was: {formatted_time} {confidence}')\n",
        "       print(f\"Actual Processing time: {formatted_process_time}\")\n",
        "      else:\n",
        "       print(f\"Processing time: {formatted_process_time}\")\n",
        "\n",
        "    #store processing stats and upload them back to the s3 bucket\n",
        "    store_processing_stats(input_resolution, input_fps, input_length, resolution_scale, upscaler, process_time)\n",
        "    try:\n",
        "      s3.upload_file(stats_file, bucket_name, object_key)\n",
        "      if os.path.isfile(temp_output):\n",
        "        print(\"Loading video preview...\")\n",
        "        showVideo(temp_output)\n",
        "      print(f\"Processing stats have been uploaded to improve processing time predictions for everyone :)\")\n",
        "    except:\n",
        "      if os.path.isfile(temp_output):\n",
        "        print(\"Loading video preview...\")\n",
        "        showVideo(temp_output)\n",
        "\n",
        "  else:\n",
        "    print(f\"Processing failed! :( see line above ðŸ‘†\")\n",
        "  \n",
        "  if os.path.isfile(stats_file):\n",
        "    os.remove(stats_file)\n",
        "  if batch_process == False:\n",
        "    print(\"Batch Processing disabled\")\n",
        "    break\n",
        "  if filenumber == None:\n",
        "    print(\"File doesn't end in a number - unable to batch process\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To do: check if all processed videos exist at the end of a batch and show an error if not.\n",
        "\n",
        "Maybe incorporate original Wav2Lip for people who just want it quck and dirty, you filthy sluts."
      ],
      "metadata": {
        "id": "T9nNCjQsmu0k"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
